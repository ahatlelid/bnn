{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#import os\n",
    "from utils.model3 import Net_mask\n",
    "#from utils.data import Data\n",
    "#from utils.loss_experiment import Loss\n",
    "#from scripts.parameters import get_parameters\n",
    "import torch\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "model_ML_inf = Net_mask()\n",
    "model_MAP_e4 = Net_mask()\n",
    "model_MAP_e4_R100 = Net_mask()\n",
    "model_MAP_e5 = Net_mask()\n",
    "model_MAP_e6 = Net_mask()\n",
    "model_MAP_e6_R100 = Net_mask()\n",
    "model_ML_inf_reg = Net_mask()\n",
    "model_ML_inf_reg_10 = Net_mask()\n",
    "model_ML_inf.load_state_dict(torch.load(f'../saved_models/model_infinite/2/model_weights.pth'))\n",
    "model_MAP_e4.load_state_dict(torch.load(f'../saved_models/finite_long_e4/map/0/model_weights.pth'))\n",
    "model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e4_100/map/0/model_weights.pth'))\n",
    "model_MAP_e5.load_state_dict(torch.load(f'../saved_models/finite_long_e5/map/0/model_weights.pth'))\n",
    "model_MAP_e6.load_state_dict(torch.load(f'../saved_models/finite_long_e6/map/0/model_weights.pth'))\n",
    "model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e6_100/map/0/model_weights.pth'))\n",
    "model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/model_infinite/3_regularization/model_weights.pth'))\n",
    "model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/model_infinite/4_reg_10/model_weights.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "tensor_D = torch.tensor(\n",
    "    [[1, -1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, -1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  1, -1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 1, -1, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 1, -1, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 1, -1, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 1, -1, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 1, -1, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 0, 1, -1],\n",
    "    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 1],], dtype=torch.float\n",
    ")\n",
    "tensor_Q_m  = torch.mm(torch.t(tensor_D), tensor_D)\n",
    "n_param = tensor_D.size(dim=0)\n",
    "#tau2 = 1000 # 1/tau2 is the noise added to the diagonal\n",
    "#tensor_Q_m_modified = tensor_Q_m + torch.eye(n_param)*(1./tau2)\n",
    "#sigma2_eps = 0.01  # 1/sigma2_eps is the factor before the likelihood\n",
    "#tensor_mu_m = torch.zeros(n_param)\n",
    "\n",
    "#tensor_Sigma_m = torch.inverse(tensor_Q_m_modified)\n",
    "#tensor_Sigma_eps = torch.eye(n_param)*sigma2_eps\n",
    "#tensor_mu_eps = tensor_mu_m "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "all_test_obses = torch.load(f'../data/test_observations/test_set_full/all_test_obses.pt')\n",
    "all_test_solutions = torch.load(f'../data/test_observations/test_set_full/all_test_solutions.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "def loss(predicted, analytical):\n",
    "    difference = predicted - analytical\n",
    "    squared_error = torch.square(difference)\n",
    "    tensor_squared_error_sum = torch.sum(squared_error, dim=1)\n",
    "    tensor_squared_error_sum_all = torch.sum(tensor_squared_error_sum)\n",
    "    return tensor_squared_error_sum_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "max_points = 6\n",
    "n_bnn = 100\n",
    "n_data = all_test_obses.shape[1]\n",
    "\n",
    "loss_ML_inf = torch.zeros(max_points)\n",
    "loss_ML_inf_reg = torch.zeros(max_points)\n",
    "loss_ML_inf_reg_10 = torch.zeros(max_points)\n",
    "loss_MAP_e4 = torch.zeros(max_points)\n",
    "loss_MAP_e4_R100 = torch.zeros(max_points)\n",
    "loss_MAP_e5 = torch.zeros(max_points)\n",
    "loss_MAP_e6 = torch.zeros(max_points)\n",
    "loss_MAP_e6_R100 = torch.zeros(max_points)\n",
    "\n",
    "loss_RML_e4_0 = torch.zeros(max_points)\n",
    "loss_RML_e4_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_median = torch.zeros(max_points)\n",
    "loss_RML_e4_variance = torch.zeros(max_points)\n",
    "loss_RML_e5_0 = torch.zeros(max_points)\n",
    "loss_RML_e5_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_median = torch.zeros(max_points)\n",
    "loss_RML_e5_variance = torch.zeros(max_points)\n",
    "\n",
    "for p in range(max_points):\n",
    "    test_set_points = all_test_obses[p]\n",
    "    test_set_solution = all_test_solutions[p]\n",
    "\n",
    "    pred_RML_e4_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    pred_RML_e5_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    for i in range(n_bnn):\n",
    "        model_RML_e4 = Net_mask()\n",
    "        model_RML_e4.load_state_dict(torch.load(f'../saved_models/rml_100_1.0e+04/pos/{i}/model_weights.pth'))\n",
    "        pred_RML_e4_all[i] = model_RML_e4(test_set_points)\n",
    "\n",
    "        model_RML_e5 = Net_mask()\n",
    "        model_RML_e5.load_state_dict(torch.load(f'../saved_models/rml_100/pos/{i}/model_weights.pth'))\n",
    "        pred_RML_e5_all[i] = model_RML_e5(test_set_points)\n",
    "\n",
    "    loss_ML_inf[p] = loss(model_ML_inf(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg[p] = loss(model_ML_inf_reg(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg_10[p] = loss(model_ML_inf_reg_10(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4[p] = loss(model_MAP_e4(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4_R100[p] = loss(model_MAP_e4_R100(test_set_points), test_set_solution)\n",
    "    loss_MAP_e5[p] = loss(model_MAP_e5(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6[p] = loss(model_MAP_e6(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6_R100[p] = loss(model_MAP_e6_R100(test_set_points), test_set_solution)\n",
    "\n",
    "    loss_RML_e4_0[p] = loss(pred_RML_e4_all[0], test_set_solution)\n",
    "    loss_RML_e4_mean[p] = loss(torch.mean(pred_RML_e4_all, dim=0), test_set_solution)\n",
    "    loss_RML_e4_median[p] = loss(torch.median(pred_RML_e4_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e4_variance[p] = torch.mean(torch.var(pred_RML_e4_all, dim=0))\n",
    "\n",
    "    loss_RML_e5_0[p] = loss(pred_RML_e5_all[0], test_set_solution)\n",
    "    loss_RML_e5_mean[p] = loss(torch.mean(pred_RML_e5_all, dim=0), test_set_solution)\n",
    "    loss_RML_e5_median[p] = loss(torch.median(pred_RML_e5_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e5_variance[p] = torch.mean(torch.var(pred_RML_e5_all, dim=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "a = torch.reshape(torch.range(1, 24, 1), (2, 3, 4))\n",
    "print(a)\n",
    "#print(torch.mean(a, dim=0).shape)\n",
    "#print(torch.median(a, dim=0)[0].shape)\n",
    "#print(torch.mean(torch.var(a, dim=2), dim=1))\n",
    "print(torch.mean(torch.var(a, dim=0)))\n",
    "#print(a[:,0,0])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  4.],\n",
      "         [ 5.,  6.,  7.,  8.],\n",
      "         [ 9., 10., 11., 12.]],\n",
      "\n",
      "        [[13., 14., 15., 16.],\n",
      "         [17., 18., 19., 20.],\n",
      "         [21., 22., 23., 24.]]])\n",
      "tensor(72.)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/pq/v4rj59917053v7zk70nqchsc0000gn/T/ipykernel_72610/2994698491.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  a = torch.reshape(torch.range(1, 24, 1), (2, 3, 4))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "title = f'{\"Type\":13} | {\"data\":4} | {1:7} | {2:7} | {3:7} | {4:7} | {5:7} | {6:7} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":13} | {\"inf\":4} |'\n",
    "#string_ML_inf_reg = f'{\"ML-inf-reg\":13} | {\"inf\":4} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":13} | {\"inf\":4} |'\n",
    "string_ML_inf_reg_10 = f'{\"ML-inf-reg_10\":13} | {\"inf\":4} |'\n",
    "\n",
    "string_MAP_e4 = f'{\"MAP-e4\":13} | {\"1e4\":4} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":13} | {\"1e4\":4} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":13} | {\"1e5\":4} |'\n",
    "string_MAP_e6 = f'{\"MAP-e6\":13} | {\"1e6\":4} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":13} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-0\":13} | {\"1e4\":4} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":13} | {\"1e4\":4} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":13} | {\"1e4\":4} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-0\":13} | {\"1e5\":4} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":13} | {\"1e5\":4} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":13} | {\"1e5\":4} |'\n",
    "\n",
    "string_RML_e6_0 = f'{\"RML-e6-0\":13} | {\"1e6\":4} |'\n",
    "string_RML_e6_mean = f'{\"RML-e6-mean\":13} | {\"1e6\":4} |'\n",
    "string_RML_e6_median = f'{\"RML-e6-median\":13} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":13} | {\"1e4\":4} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":13} | {\"1e5\":4} |'\n",
    "\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_ML_inf += f' {loss_ML_inf[i]:7.2f} |' \n",
    "    string_ML_inf_reg += f' {loss_ML_inf_reg[i]:7.2f} |' \n",
    "    string_ML_inf_reg_10 += f' {loss_ML_inf_reg_10[i]:7.2f} |' \n",
    "\n",
    "    string_MAP_e4 += f' {loss_MAP_e4[i]:7.2f} |' \n",
    "    string_MAP_e4_R100 += f' {loss_MAP_e4_R100[i]:7.2f} |' \n",
    "    string_MAP_e5 += f' {loss_MAP_e5[i]:7.2f} |' \n",
    "    string_MAP_e6 += f' {loss_MAP_e6[i]:7.2f} |' \n",
    "    string_MAP_e6_R100 += f' {loss_MAP_e6_R100[i]:7.2f} |' \n",
    "\n",
    "    string_RML_e4_0 += f' {loss_RML_e4_0[i]:7.2f} |' \n",
    "    string_RML_e4_mean += f' {loss_RML_e4_mean[i]:7.2f} |' \n",
    "    string_RML_e4_median += f' {loss_RML_e4_median[i]:7.2f} |' \n",
    "\n",
    "    string_RML_e5_0 += f' {loss_RML_e5_0[i]:7.2f} |' \n",
    "    string_RML_e5_mean += f' {loss_RML_e5_mean[i]:7.2f} |' \n",
    "    string_RML_e5_median += f' {loss_RML_e5_median[i]:7.2f} |' \n",
    "\n",
    "    string_RML_e4_var += f' {loss_RML_e4_variance[i]:7.4f} |' \n",
    "    string_RML_e5_var += f' {loss_RML_e5_variance[i]:7.4f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*82\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_ML_inf_reg_10); total_string+=string_ML_inf_reg_10+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "print(string_MAP_e4_R100); total_string+=string_MAP_e4_R100+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_MAP_e6); total_string+=string_MAP_e6+'\\n'\n",
    "print(string_MAP_e6_R100); total_string+=string_MAP_e6_R100+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_var); total_string+=string_RML_e4_var+'\\n'\n",
    "print(string_RML_e5_var); total_string+=string_RML_e5_var+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Type          | data |       1 |       2 |       3 |       4 |       5 |       6 |\n",
      "----------------------------------------------------------------------------------\n",
      "ML-inf        | inf  |  625.19 |   65.79 |  192.65 |  144.46 |   77.31 |   37.18 |\n",
      "MAP-inf       | inf  |  443.55 |   41.70 |  150.94 |  100.98 |   47.48 |   22.96 |\n",
      "----------------------------------------------------------------------------------\n",
      "MAP-e4        | 1e4  | 1088.65 |  179.28 |  198.51 |  142.28 |   77.93 |   39.00 |\n",
      "MAP-e5        | 1e5  |  644.86 |   95.18 |  210.09 |  153.28 |   75.92 |   34.89 |\n",
      "MAP-e6        | 1e6  |  663.73 |   81.26 |  196.81 |  154.13 |   79.78 |   39.50 |\n",
      "----------------------------------------------------------------------------------\n",
      "RML-e4-0      | 1e4  | 7915.40 | 3581.10 | 2637.34 | 2258.67 | 1755.92 | 1319.39 |\n",
      "RML-e4-mean   | 1e4  | 7640.74 | 3269.30 | 2368.23 | 2021.99 | 1533.36 | 1144.55 |\n",
      "RML-e4-median | 1e4  | 7650.73 | 3284.09 | 2380.90 | 2033.89 | 1543.08 | 1152.27 |\n",
      "----------------------------------------------------------------------------------\n",
      "RML-e5-0      | 1e5  | 5960.25 | 1708.21 |  931.59 |  636.99 |  367.80 |  205.19 |\n",
      "RML-e5-mean   | 1e5  | 5878.91 | 1653.07 |  895.55 |  585.42 |  321.32 |  174.47 |\n",
      "RML-e5-median | 1e5  | 5894.10 | 1656.29 |  897.32 |  587.57 |  323.64 |  176.46 |\n",
      "----------------------------------------------------------------------------------\n",
      "RML-e4-var    | 1e4  |  0.0055 |  0.0078 |  0.0091 |  0.0102 |  0.0111 |  0.0120 |\n",
      "RML-e5-var    | 1e5  |  0.0017 |  0.0020 |  0.0021 |  0.0021 |  0.0020 |  0.0018 |\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "with open('../figures/plot_table_prediction_error/plot_table_prediction_error.txt', 'w') as outfile:\n",
    "    outfile.write(total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.4 64-bit ('pytorch_env': conda)"
  },
  "interpreter": {
   "hash": "24726422bde522ec9d6b8250d1636c6a7c473f035d7185ba3e11c63b1681e397"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}