{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import shutil\n",
    "from utils.model import Net_mask\n",
    "\n",
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# seeds\n",
    "# 1 Traing data 10^4\n",
    "# 2 Training data 10^5\n",
    "# 3 Test data 10^3 x 6\n",
    "# x 10-15, 20-25, ..., 60-65\n",
    "# 4 RML noise to 10^4 obses\n",
    "# 5 RML noise to 10^5 obses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Common for all data generation\n",
    "n_param = 10\n",
    "data_var = 1\n",
    "data_mean = torch.zeros(n_param)\n",
    "data_covariance = torch.eye(n_param)*data_var"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Generate trainin data 10^4\n",
    "torch.manual_seed(1)\n",
    "n_data = int(1e4)\n",
    "\n",
    "tensor_data = torch.zeros(n_data, 2*n_param)\n",
    "tensor_d_sample =  MultivariateNormal(loc=data_mean, covariance_matrix=data_covariance).sample(sample_shape=(n_data,))\n",
    "tensor_n_masked = torch.randint(1, n_param+1, (n_data,))\n",
    "tensor_masks = torch.rand(n_data, n_param).argsort(dim=1)\n",
    "tensor_masks = (tensor_masks < tensor_n_masked.unsqueeze(1))*1\n",
    "tensor_data[:,:n_param] = tensor_d_sample*tensor_masks\n",
    "tensor_data[:,n_param:] = tensor_masks\n",
    "torch.save(tensor_data, f'../data/@/1.0e+04/data/data.pt')\n",
    "torch.save(tensor_d_sample, f'../data/@/1.0e+04/data/data_obses/data_obses.pt')\n",
    "torch.save(tensor_masks, f'../data/@/1.0e+04/data/data_masks/data_masks.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# generate trainig data 10^5\n",
    "torch.manual_seed(2)\n",
    "n_data = int(1e5)\n",
    "\n",
    "tensor_data = torch.zeros(n_data, 2*n_param)\n",
    "tensor_d_sample =  MultivariateNormal(loc=data_mean, covariance_matrix=data_covariance).sample(sample_shape=(n_data,))\n",
    "tensor_n_masked = torch.randint(1, n_param+1, (n_data,))\n",
    "tensor_masks = torch.rand(n_data, n_param).argsort(dim=1)\n",
    "tensor_masks = (tensor_masks < tensor_n_masked.unsqueeze(1))*1\n",
    "tensor_data[:,:n_param] = tensor_d_sample*tensor_masks\n",
    "tensor_data[:,n_param:] = tensor_masks\n",
    "torch.save(tensor_data, f'../data/@/1.0e+05/data/data.pt')\n",
    "torch.save(tensor_d_sample, f'../data/@/1.0e+05/data/data_obses/data_obses.pt')\n",
    "torch.save(tensor_masks, f'../data/@/1.0e+05/data/data_masks/data_masks.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# generate test set 6x1000 obses\n",
    "torch.manual_seed(3)\n",
    "\n",
    "n_data = int(1e3)\n",
    "\n",
    "n_max_points = 6\n",
    "test_data = torch.zeros(n_max_points, n_data, 2*n_param)\n",
    "for i in range(n_max_points):\n",
    "    tensor_data = torch.zeros(n_data, 2*n_param)\n",
    "    tensor_d_sample =  MultivariateNormal(loc=data_mean, covariance_matrix=data_covariance).sample(sample_shape=(n_data,))\n",
    "    tensor_masks = torch.rand(n_data, n_param).argsort(dim=1)\n",
    "    tensor_masks = (tensor_masks < i+1)*1\n",
    "    tensor_data[:,:n_param] = tensor_d_sample*tensor_masks\n",
    "    tensor_data[:,n_param:] = tensor_masks\n",
    "    test_data[i] = tensor_data\n",
    "torch.save(test_data, f'../data/@/test_data/1.0e+03/test_data.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# manual seeds 10-15, 20-25, ..., 60-65\n",
    "\n",
    "n_data_points = 6\n",
    "n_points_max = 6\n",
    "all_points = torch.zeros(100, 2*n_param)\n",
    "n_data = 1\n",
    "\n",
    "for i in range(n_points_max):\n",
    "    for j in range(n_data_points):\n",
    "        torch.manual_seed(f'{i+1}{j}') # seeds 10-15, 20-25, ..., 60-65\n",
    "        tensor_data = torch.zeros(n_data, 2*n_param)\n",
    "        tensor_d_sample =  MultivariateNormal(loc=data_mean, covariance_matrix=data_covariance).sample(sample_shape=(n_data,))\n",
    "        tensor_n_masked = torch.Tensor([i+1])\n",
    "        tensor_masks = torch.rand(n_data, n_param).argsort(dim=1)\n",
    "        tensor_masks = (tensor_masks < tensor_n_masked)*1\n",
    "        tensor_data[:,:n_param] = tensor_d_sample*tensor_masks\n",
    "        tensor_data[:,n_param:] = tensor_masks\n",
    "        all_points[int(f'{i+1}{j}'),:] = tensor_data\n",
    "torch.save(all_points, f'../data/@/test_data/test_observations/all_test_observations.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tensor_D = torch.tensor(\n",
    "    [[1, -1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, -1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  1, -1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 1, -1, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 1, -1, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 1, -1, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 1, -1, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 1, -1, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 0, 1, -1],\n",
    "    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 1],], dtype=torch.float\n",
    ")\n",
    "tensor_Q_m = torch.mm(torch.t(tensor_D), tensor_D) \n",
    "n_param = tensor_D.size(dim=0)\n",
    "vu = 10000\n",
    "inversion_scaling = 1/vu\n",
    "tensor_Q_m_modified = tensor_Q_m + torch.ones(n_param)*inversion_scaling \n",
    "tensor_Sigma_m = torch.inverse(tensor_Q_m_modified)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# RML noise 10^4\n",
    "torch.manual_seed(4)\n",
    "\n",
    "sigma2 = 0.1**2 #=0.01\n",
    "tau2 = 0.3**2 #=0.09\n",
    "model = Net_mask()\n",
    "n_weights = sum(p.numel() for p in model.parameters())\n",
    "n_data = int(1e4)\n",
    "n_bnn = 100\n",
    "\n",
    "for i in range(n_bnn):\n",
    "    path = f'../data/@/1.0e+04/rml_noise/{i}/'\n",
    "    #os.makedirs(path)\n",
    "    noise_data = MultivariateNormal(loc=torch.zeros(n_param), covariance_matrix=(torch.eye(n_param)*sigma2)).sample(sample_shape=(n_data,))\n",
    "    noise_data_regularization =  MultivariateNormal(loc=torch.zeros(n_param), covariance_matrix=(tensor_Sigma_m)).sample(sample_shape=(n_data,))\n",
    "    noise_parameter = torch.t(MultivariateNormal(loc=torch.zeros(1), covariance_matrix=(torch.eye(1)*tau2)).sample(sample_shape=(n_weights,)))\n",
    "    torch.save(noise_data, f'{path}noise_data.pt')\n",
    "    torch.save(noise_data_regularization, f'{path}noise_data_regularization.pt')\n",
    "    torch.save(noise_parameter, f'{path}noise_parameter.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# RML noise 10^5\n",
    "torch.manual_seed(5)\n",
    "\n",
    "sigma2 = 0.1**2 #=0.01\n",
    "tau2 = 0.3**2 #=0.09\n",
    "model = Net_mask()\n",
    "n_weights = sum(p.numel() for p in model.parameters())\n",
    "n_data = int(1e5)\n",
    "n_bnn = 100\n",
    "\n",
    "for i in range(n_bnn):\n",
    "    path = f'../data/@/1.0e+05/rml_noise/{i}/'\n",
    "    #os.makedirs(path)\n",
    "    noise_data = MultivariateNormal(loc=torch.zeros(n_param), covariance_matrix=(torch.eye(n_param)*sigma2)).sample(sample_shape=(n_data,))\n",
    "    noise_data_regularization =  MultivariateNormal(loc=torch.zeros(n_param), covariance_matrix=(tensor_Sigma_m)).sample(sample_shape=(n_data,))\n",
    "    noise_parameter = torch.t(MultivariateNormal(loc=torch.zeros(1), covariance_matrix=(torch.eye(1)*tau2)).sample(sample_shape=(n_weights,)))\n",
    "    torch.save(noise_data, f'{path}noise_data.pt')\n",
    "    torch.save(noise_data_regularization, f'{path}noise_data_regularization.pt')\n",
    "    torch.save(noise_parameter, f'{path}noise_parameter.pt')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.4 64-bit ('pytorch_env': conda)"
  },
  "interpreter": {
   "hash": "24726422bde522ec9d6b8250d1636c6a7c473f035d7185ba3e11c63b1681e397"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}