{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#import os\n",
    "from utils.model import Net_mask\n",
    "import torch\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model_ML_inf = Net_mask()\n",
    "model_MAP_e4 = Net_mask()\n",
    "model_MAP_e4_R100 = Net_mask()\n",
    "model_MAP_e5 = Net_mask()\n",
    "model_MAP_e6 = Net_mask()\n",
    "model_MAP_e6_R100 = Net_mask()\n",
    "model_ML_inf_reg = Net_mask()\n",
    "model_ML_inf_reg_10 = Net_mask()\n",
    "\n",
    "#model_ML_inf.load_state_dict(torch.load(f'../saved_models/models_infinite_data/ML/model_weights.pth'))\n",
    "#model_MAP_e4.load_state_dict(torch.load(f'../saved_models/finite_long_e4/map/0/model_weights.pth'))\n",
    "#model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e4_100/map/0/model_weights.pth'))\n",
    "#model_MAP_e5.load_state_dict(torch.load(f'../saved_models/finite_long_e5/map/0/model_weights.pth'))\n",
    "#model_MAP_e6.load_state_dict(torch.load(f'../saved_models/finite_long_e6/map/0/model_weights.pth'))\n",
    "#model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e6_100/map/0/model_weights.pth'))\n",
    "#model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_100/model_weights.pth'))\n",
    "#model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_10/model_weights.pth'))\n",
    "\n",
    "\n",
    "model_ML_inf.load_state_dict(torch.load(f'../saved_models/models_infinite_data/ML/model_weights.pth'))\n",
    "model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_100/model_weights.pth'))\n",
    "model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_10/model_weights.pth'))\n",
    "#model_MAP_e4.load_state_dict(torch.load(f'../saved_models/models_finite_data/e4/prior_10/model_weights.pth'))\n",
    "model_MAP_e4.load_state_dict(torch.load(f'../saved_models/testing/map2/long/e4/1/model_weights.pth'))\n",
    "model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/models_finite_data/e4/prior_100/model_weights.pth'))\n",
    "#model_MAP_e5.load_state_dict(torch.load(f'../saved_models/models_finite_data/e5/prior_100/model_weights.pth'))\n",
    "model_MAP_e5.load_state_dict(torch.load(f'../saved_models/testing/map/long/e5/0/model_weights.pth'))\n",
    "model_MAP_e6.load_state_dict(torch.load(f'../saved_models/models_finite_data/e6/prior_1000/model_weights.pth'))\n",
    "model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/models_finite_data/e6/prior_100/model_weights.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tensor_D = torch.tensor(\n",
    "    [[1, -1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, -1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  1, -1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 1, -1, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 1, -1, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 1, -1, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 1, -1, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 1, -1, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 0, 1, -1],\n",
    "    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 1],], dtype=torch.float\n",
    ")\n",
    "tensor_Q_m  = torch.mm(torch.t(tensor_D), tensor_D)\n",
    "n_param = tensor_D.size(dim=0)\n",
    "#tau2 = 1000 # 1/tau2 is the noise added to the diagonal\n",
    "#tensor_Q_m_modified = tensor_Q_m + torch.eye(n_param)*(1./tau2)\n",
    "#sigma2_eps = 0.01  # 1/sigma2_eps is the factor before the likelihood\n",
    "#tensor_mu_m = torch.zeros(n_param)\n",
    "\n",
    "#tensor_Sigma_m = torch.inverse(tensor_Q_m_modified)\n",
    "#tensor_Sigma_eps = torch.eye(n_param)*sigma2_eps\n",
    "#tensor_mu_eps = tensor_mu_m "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "all_test_obses = torch.load(f'../data/test_observations/test_set_full/all_test_obses.pt')\n",
    "all_test_solutions = torch.load(f'../data/test_observations/test_set_full/all_test_solutions.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def loss(predicted, analytical):\n",
    "    difference = predicted - analytical\n",
    "    squared_error = torch.square(difference)\n",
    "    tensor_squared_error_sum = torch.sum(squared_error, dim=1)\n",
    "    tensor_squared_error_sum_all = torch.sum(tensor_squared_error_sum)\n",
    "    return tensor_squared_error_sum_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "max_points = 6\n",
    "n_data = all_test_obses.shape[1]\n",
    "\n",
    "#f_list = list(range(0, 20)) + list(range(20, 28)) + list(range(60, 65)) + [81, 82] + list(range(96, 100))\n",
    "#f_list = list(range(0, 19)) + list(range(20, 27)) + list(range(60, 65)) + [81, 82] + list(range(96, 100))\n",
    "#f_list = list(range(31)) + list(range(60, 68)) + [70] + list(range(80, 85)) + list(range(92, 100))\n",
    "#f_list = list(range(34)) + list(range(60, 72)) + list(range(80,88)) + list(range(92, 100))\n",
    "f_list = list(range(48)) + list(range(51, 100)) \n",
    "f_length = len(f_list)\n",
    "n_bnn = f_length\n",
    "loss_RML_e4_all = torch.zeros(max_points, n_bnn)\n",
    "loss_RML_e5_all = torch.zeros(max_points, n_bnn)\n",
    "\n",
    "loss_ML_inf = torch.zeros(max_points)\n",
    "loss_ML_inf_reg = torch.zeros(max_points)\n",
    "loss_ML_inf_reg_10 = torch.zeros(max_points)\n",
    "loss_MAP_e4 = torch.zeros(max_points)\n",
    "loss_MAP_e4_R100 = torch.zeros(max_points)\n",
    "loss_MAP_e5 = torch.zeros(max_points)\n",
    "loss_MAP_e6 = torch.zeros(max_points)\n",
    "loss_MAP_e6_R100 = torch.zeros(max_points)\n",
    "\n",
    "loss_RML_e4_0 = torch.zeros(max_points)\n",
    "loss_RML_e4_n_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_median = torch.zeros(max_points)\n",
    "loss_RML_e4_variance = torch.zeros(max_points)\n",
    "loss_RML_e5_0 = torch.zeros(max_points)\n",
    "loss_RML_e5_n_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_median = torch.zeros(max_points)\n",
    "loss_RML_e5_variance = torch.zeros(max_points)\n",
    "\n",
    "for p in range(max_points):\n",
    "    test_set_points = all_test_obses[p]\n",
    "    test_set_solution = all_test_solutions[p]\n",
    "\n",
    "    #i_list = list(range(26)) + list(range(83, 100))\n",
    "    #i_list = list(range(12)) + list(range(96, 100))\n",
    "\n",
    "    pred_RML_e4_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    pred_RML_e5_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    \n",
    "    for idx, item in enumerate(f_list):\n",
    "        model_RML_e4 = Net_mask()\n",
    "        model_RML_e4.load_state_dict(torch.load(f'../saved_models/testing/rml/long/e4/{item}/model_weights.pth'))\n",
    "        pred_RML_e4_all[idx] = model_RML_e4(test_set_points)\n",
    "        loss_RML_e4_all[p,idx] = loss(pred_RML_e4_all[idx], test_set_solution)\n",
    "\n",
    "    #i_list = list(range(35)) + list(range(92, 100))\n",
    "    #i_list = list(range(12)) + list(range(96, 100))\n",
    "    for idx, item in enumerate(f_list):\n",
    "        model_RML_e5 = Net_mask()\n",
    "        model_RML_e5.load_state_dict(torch.load(f'../saved_models/testing/rml/long/e5/{item}/model_weights.pth'))\n",
    "        pred_RML_e5_all[idx] = model_RML_e5(test_set_points)\n",
    "        loss_RML_e5_all[p,idx] = loss(pred_RML_e5_all[idx], test_set_solution)\n",
    "\n",
    "    loss_ML_inf[p] = loss(model_ML_inf(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg[p] = loss(model_ML_inf_reg(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg_10[p] = loss(model_ML_inf_reg_10(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4[p] = loss(model_MAP_e4(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4_R100[p] = loss(model_MAP_e4_R100(test_set_points), test_set_solution)\n",
    "    loss_MAP_e5[p] = loss(model_MAP_e5(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6[p] = loss(model_MAP_e6(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6_R100[p] = loss(model_MAP_e6_R100(test_set_points), test_set_solution)\n",
    "\n",
    "    loss_RML_e4_0[p] = loss(pred_RML_e4_all[0], test_set_solution)\n",
    "    loss_RML_e4_n_mean[p] = torch.mean(loss_RML_e4_all[p], dim=0)\n",
    "    loss_RML_e4_mean[p] = loss(torch.mean(pred_RML_e4_all, dim=0), test_set_solution)\n",
    "    loss_RML_e4_median[p] = loss(torch.median(pred_RML_e4_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e4_variance[p] = torch.mean(torch.var(pred_RML_e4_all, dim=0))\n",
    "\n",
    "    loss_RML_e5_0[p] = loss(pred_RML_e5_all[0], test_set_solution)\n",
    "    loss_RML_e5_n_mean[p] = torch.mean(loss_RML_e5_all[p], dim=0)\n",
    "    loss_RML_e5_mean[p] = loss(torch.mean(pred_RML_e5_all, dim=0), test_set_solution)\n",
    "    loss_RML_e5_median[p] = loss(torch.median(pred_RML_e5_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e5_variance[p] = torch.mean(torch.var(pred_RML_e5_all, dim=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "loss_RML_e4_all.shape\n",
    "print(torch.min(loss_RML_e4_all[0]))\n",
    "print(torch.min(loss_RML_e4_all, dim=1)[0])\n",
    "print(torch.quantile(loss_RML_e4_all, 0.1, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all[0], 0.1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.5, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.9, dim=1))\n",
    "print(torch.max(loss_RML_e4_all, dim=1)[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2589.1177, grad_fn=<MinBackward1>)\n",
      "tensor([2589.1177,  635.2662,  496.7845,  409.7758,  283.2042,  181.3043],\n",
      "       grad_fn=<MinBackward0>)\n",
      "tensor([3160.9712,  702.9885,  537.4078,  448.8858,  314.5657,  210.7247],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor(3160.9712, grad_fn=<SqueezeBackward3>)\n",
      "tensor([3652.0906,  839.3186,  591.0293,  490.6874,  351.7557,  237.7041],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([4539.4575, 1162.2141,  744.5953,  578.3859,  390.0454,  274.4622],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([5569.9990, 1578.6849,  877.0135,  625.9697,  429.1646,  290.1434],\n",
      "       grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "title = f'{\"Model/statistic\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":15} |'\n",
    "#string_ML_inf_reg = f'{\"ML-inf-reg\":15} | {\"inf\":4} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":15} |'\n",
    "string_ML_inf_reg_10 = f'{\"ML-inf-reg_10\":15} |'\n",
    "\n",
    "string_MAP_e4 = f'{\"MAP-e4\":15} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":15} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":15} |'\n",
    "string_MAP_e6 = f'{\"MAP-e6\":15} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":15} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-1\":15} |'\n",
    "string_RML_e4_n_mean = f'{\"RML-e4\":15} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":15} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":15} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-1\":15} |'\n",
    "string_RML_e5_n_mean = f'{\"RML-e5\":15} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":15} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":15} |'\n",
    "\n",
    "#string_RML_e6_0 = f'{\"RML-e6-0\":15} | {\"1e6\":4} |'\n",
    "#string_RML_e6_mean = f'{\"RML-e6-mean\":15} | {\"1e6\":4} |'\n",
    "#string_RML_e6_median = f'{\"RML-e6-median\":15} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":15} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":15} |'\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_ML_inf += f' {loss_ML_inf[i]:8.2f} |' \n",
    "    string_ML_inf_reg += f' {loss_ML_inf_reg[i]:8.2f} |' \n",
    "    string_ML_inf_reg_10 += f' {loss_ML_inf_reg_10[i]:8.2f} |' \n",
    "\n",
    "    string_MAP_e4 += f' {loss_MAP_e4[i]:8.2f} |' \n",
    "    string_MAP_e4_R100 += f' {loss_MAP_e4_R100[i]:8.2f} |' \n",
    "    string_MAP_e5 += f' {loss_MAP_e5[i]:8.2f} |' \n",
    "    string_MAP_e6 += f' {loss_MAP_e6[i]:8.2f} |' \n",
    "    string_MAP_e6_R100 += f' {loss_MAP_e6_R100[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e4_0 += f' {loss_RML_e4_0[i]:8.2f} |' \n",
    "    string_RML_e4_n_mean += f' {loss_RML_e4_n_mean[i]:8.2f} |'\n",
    "    string_RML_e4_mean += f' {loss_RML_e4_mean[i]:8.2f} |' \n",
    "    string_RML_e4_median += f' {loss_RML_e4_median[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e5_0 += f' {loss_RML_e5_0[i]:8.2f} |' \n",
    "    string_RML_e5_n_mean += f' {loss_RML_e5_n_mean[i]:8.2f} |'\n",
    "    string_RML_e5_mean += f' {loss_RML_e5_mean[i]:8.2f} |' \n",
    "    string_RML_e5_median += f' {loss_RML_e5_median[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e4_var += f' {loss_RML_e4_variance[i]:8.4f} |' \n",
    "    string_RML_e5_var += f' {loss_RML_e5_variance[i]:8.4f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*83\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "#print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "#print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "#print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "#print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model/statistic | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4-mean     |  3633.81 |   696.17 |   405.81 |   295.33 |   163.23 |    78.13 |\n",
      "RML-e4-median   |  3663.74 |   705.02 |   413.07 |   302.74 |   170.10 |    83.12 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e5-mean     |  1598.52 |   168.86 |   203.49 |   149.79 |    76.85 |    32.35 |\n",
      "RML-e5-median   |  1622.05 |   173.90 |   205.56 |   150.71 |    77.49 |    32.58 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#with open('../figures/plot_table_prediction_error/plot_table_prediction_error.txt', 'w') as outfile:\n",
    "#    outfile.write('\\n\\n' + total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "title = f'{\"Model\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "total_string = \"\"\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "#with open('../figures/plot_table_prediction_error/plot_table_prediction_error_inf.txt', 'w') as outfile_inf:\n",
    "#    outfile_inf.write(total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "ML-inf          |   625.19 |    65.79 |   192.65 |   144.46 |    77.31 |    37.18 |\n",
      "MAP-inf         |   443.55 |    41.70 |   150.94 |   100.98 |    47.48 |    22.96 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\n",
    "title = f'{\"Model\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "total_string = \"\"\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "#print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "#print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "#with open('../figures/plot_table_prediction_error/plot_table_prediction_error_map.txt', 'w') as outfile_inf:\n",
    "#    outfile_inf.write(total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "MAP-e4          |  1698.63 |   186.28 |   224.47 |   174.53 |    98.46 |    48.55 |\n",
      "MAP-e5          |   936.00 |   114.62 |   208.32 |   162.86 |    79.37 |    36.78 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "title = f'{\"Model\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "\n",
    "total_string = \"\"\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "#with open('../figures/plot_table_prediction_error/plot_table_prediction_error_RML_n.txt', 'w') as outfile_inf:\n",
    "#    outfile_inf.write(total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4          |  3789.14 |   892.79 |   614.85 |   501.84 |   353.09 |   240.04 |\n",
      "RML-e5          |  1688.52 |   228.99 |   255.03 |   195.70 |   117.13 |    65.11 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#with open('../figures/plot_table_prediction_error/plot_table_prediction_error_inf.txt', 'w') as outfile:\n",
    "#    outfile.write(total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\n",
    "title = f'{\"Percentile\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "title2 = f'{\"Mean\":15} {\"\":65} |'\n",
    "\n",
    "loss_RML_e4_all.shape\n",
    "#print(torch.min(loss_RML_e4_all, dim=1)[0])\n",
    "#print(torch.quantile(loss_RML_e4_all, 0.1, dim=1))\n",
    "#print(torch.quantile(loss_RML_e4_all, 0.5, dim=1))\n",
    "#print(torch.quantile(loss_RML_e4_all, 0.9, dim=1))\n",
    "#print(torch.max(loss_RML_e4_all, dim=1)[0])\n",
    "\n",
    "string_RML_e4_min = f'{\"RML-e4-min\":15} |'\n",
    "string_RML_e4_p10 = f'{\"RML-e4-p10\":15} |'\n",
    "string_RML_e4_p50 = f'{\"RML-e4-p50\":15} |'\n",
    "string_RML_e4_p90 = f'{\"RML-e4-p90\":15} |'\n",
    "string_RML_e4_max = f'{\"RML-e4-max\":15} |'\n",
    "\n",
    "string_RML_e5_min = f'{\"RML-e5-min\":15} |'\n",
    "string_RML_e5_p10 = f'{\"RML-e5-p10\":15} |'\n",
    "string_RML_e5_p50 = f'{\"RML-e5-p50\":15} |'\n",
    "string_RML_e5_p90 = f'{\"RML-e5-p90\":15} |'\n",
    "string_RML_e5_max = f'{\"RML-e5-max\":15} |'\n",
    "\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_RML_e4_min += f' {torch.min(loss_RML_e4_all[i]):8.2f} |' \n",
    "    string_RML_e4_p10 += f' {torch.quantile(loss_RML_e4_all[i], 0.1):8.2f} |'\n",
    "    string_RML_e4_p50 += f' {torch.quantile(loss_RML_e4_all[i], 0.5):8.2f} |'\n",
    "    string_RML_e4_p90 += f' {torch.quantile(loss_RML_e4_all[i], 0.9):8.2f} |'\n",
    "    string_RML_e4_max += f' {torch.max(loss_RML_e4_all[i]):8.2f} |' \n",
    "\n",
    "    string_RML_e5_min += f' {torch.min(loss_RML_e5_all[i]):8.2f} |' \n",
    "    string_RML_e5_p10 += f' {torch.quantile(loss_RML_e5_all[i], 0.1):8.2f} |'\n",
    "    string_RML_e5_p50 += f' {torch.quantile(loss_RML_e5_all[i], 0.5):8.2f} |'\n",
    "    string_RML_e5_p90 += f' {torch.quantile(loss_RML_e5_all[i], 0.9):8.2f} |'\n",
    "    string_RML_e5_max += f' {torch.max(loss_RML_e5_all[i]):8.2f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*83\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_min); total_string+=string_RML_e4_min+'\\n'\n",
    "print(string_RML_e4_p10); total_string+=string_RML_e4_p10+'\\n'\n",
    "print(string_RML_e4_p50); total_string+=string_RML_e4_p50+'\\n'\n",
    "print(string_RML_e4_p90); total_string+=string_RML_e4_p90+'\\n'\n",
    "print(string_RML_e4_max); total_string+=string_RML_e4_max+'\\n'\n",
    "\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_min); total_string+=string_RML_e5_min+'\\n'\n",
    "print(string_RML_e5_p10); total_string+=string_RML_e5_p10+'\\n'\n",
    "print(string_RML_e5_p50); total_string+=string_RML_e5_p50+'\\n'\n",
    "print(string_RML_e5_p90); total_string+=string_RML_e5_p90+'\\n'\n",
    "print(string_RML_e5_max); total_string+=string_RML_e5_max+'\\n'\n",
    "\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(title2); total_string+=title2+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentile      | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4-min      |  2589.12 |   635.27 |   496.78 |   409.78 |   283.20 |   181.30 |\n",
      "RML-e4-p10      |  3160.97 |   702.99 |   537.41 |   448.89 |   314.57 |   210.72 |\n",
      "RML-e4-p50      |  3652.09 |   839.32 |   591.03 |   490.69 |   351.76 |   237.70 |\n",
      "RML-e4-p90      |  4539.46 |  1162.21 |   744.60 |   578.39 |   390.05 |   274.46 |\n",
      "RML-e4-max      |  5570.00 |  1578.68 |   877.01 |   625.97 |   429.16 |   290.14 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e5-min      |   764.14 |   137.17 |   214.30 |   168.21 |    95.45 |    53.94 |\n",
      "RML-e5-p10      |  1192.08 |   162.77 |   234.48 |   178.87 |   104.38 |    56.94 |\n",
      "RML-e5-p50      |  1647.35 |   223.89 |   254.97 |   194.59 |   114.50 |    63.98 |\n",
      "RML-e5-p90      |  2325.18 |   295.19 |   279.71 |   215.05 |   132.38 |    76.30 |\n",
      "RML-e5-max      |  2784.27 |   374.78 |   301.48 |   238.74 |   151.86 |    88.05 |\n",
      "-----------------------------------------------------------------------------------\n",
      "Mean                                                                              |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4          |  3789.14 |   892.79 |   614.85 |   501.84 |   353.09 |   240.04 |\n",
      "RML-e5          |  1688.52 |   228.99 |   255.03 |   195.70 |   117.13 |    65.11 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\n",
    "#with open('../figures/plot_table_prediction_error/plot_table_percentile.txt', 'w') as outfile:\n",
    "#    outfile.write(total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\n",
    "title1 = f'{\"Model\":15} | {\"N train data\":12} | {\"Regularization\":14} | {\"Comment\":34} |'\n",
    "title2 = f'{\"Statistic\":15} | {\"\":12} | {\"\":14} | {\"Comment\":34} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":15} | {\"Infinite\":12} | {\"None\":14} | {\"Maximum likelihood model\":34} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":15} | {\"Infinite\":12} | {\"L_2\":14} | {\"Model with L_2 regularization\":34} |'\n",
    "\n",
    "#string_MAP_e4 = f'{\"MAP-e4\":13} | {\"1e4\":4} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":15} | {\"10^4\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^4 data\":34} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":15} | {\"10^5\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^5 data\":34} |'\n",
    "#string_MAP_e6 = f'{\"MAP-e6\":13} | {\"1e6\":4} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":15} | {\"10^6\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^6 data\":34} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-1\":15} | {\"10^4\":12} | {\"L_2 (RML)\":14} | {\"RML model number 1 with 10^4 data\":34} |'\n",
    "string_RML_e4_n_mean = f'{\"RML-e4-n-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of loss RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":15} | {\"\":12} | {\"\":14} | {\"Median of RML-e4-1 to RML-e4-25\":34} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-1\":15} | {\"10^5\":12} | {\"L_2 (RML)\":14} | {\"RML model number 1 with 10^5 data\":34} |'\n",
    "string_RML_e5_n_mean = f'{\"RML-e5-n-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of loss RML-e5-1 to RML-e5-25\":34} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e5-1 to RML-e5-25\":34} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":15} | {\"\":12} | {\"\":14} | {\"Median of RML-e5-1 to RML-e5-25\":34} |'\n",
    "\n",
    "#string_RML_e6_0 = f'{\"RML-e6-0\":13} | {\"1e6\":4} |'\n",
    "#string_RML_e6_mean = f'{\"RML-e6-mean\":13} | {\"1e6\":4} |'\n",
    "#string_RML_e6_median = f'{\"RML-e6-median\":13} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":15} | {\"\":12} | {\"\":14} | {\"Variance of RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":15} | {\"\":12} | {\"\":14} | {\"Variance of RML-e5-1 to RML-e5-25\":34} |'\n",
    "\n",
    "\n",
    "string_break = '-'*86\n",
    "total_string = \"\"\n",
    "\n",
    "print(title1); total_string+=title1+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_MAP_e4_R100); total_string+=string_MAP_e4_R100+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_MAP_e6_R100); total_string+=string_MAP_e6_R100+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "#print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "#print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "#print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "#print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(title2); total_string+=title2+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "#print(string_RML_e4_var); total_string+=string_RML_e4_var+'\\n'\n",
    "#print(string_RML_e5_var); total_string+=string_RML_e5_var+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#with open('../figures/plot_table_prediction_error/plot_table_description.txt', 'w') as outfile:\n",
    "#    outfile.write('\\n\\n' + total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | N train data | Regularization | Comment                            |\n",
      "--------------------------------------------------------------------------------------\n",
      "ML-inf          | Infinite     | None           | Maximum likelihood model           |\n",
      "MAP-inf         | Infinite     | L_2            | Model with L_2 regularization      |\n",
      "MAP-e4          | 10^4         | L_2            | L_2 reg. trained with 10^4 data    |\n",
      "MAP-e5          | 10^5         | L_2            | L_2 reg. trained with 10^5 data    |\n",
      "RML-e4-1        | 10^4         | L_2 (RML)      | RML model number 1 with 10^4 data  |\n",
      "RML-e5-1        | 10^5         | L_2 (RML)      | RML model number 1 with 10^5 data  |\n",
      "--------------------------------------------------------------------------------------\n",
      "Statistic       |              |                | Comment                            |\n",
      "--------------------------------------------------------------------------------------\n",
      "RML-e4-n-mean   |              |                | Mean of loss RML-e4-1 to RML-e4-25 |\n",
      "RML-e4-mean     |              |                | Mean of RML-e4-1 to RML-e4-25      |\n",
      "RML-e4-median   |              |                | Median of RML-e4-1 to RML-e4-25    |\n",
      "RML-e5-n-mean   |              |                | Mean of loss RML-e5-1 to RML-e5-25 |\n",
      "RML-e5-mean     |              |                | Mean of RML-e5-1 to RML-e5-25      |\n",
      "RML-e5-median   |              |                | Median of RML-e5-1 to RML-e5-25    |\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.4 64-bit ('pytorch_env': conda)"
  },
  "interpreter": {
   "hash": "24726422bde522ec9d6b8250d1636c6a7c473f035d7185ba3e11c63b1681e397"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}