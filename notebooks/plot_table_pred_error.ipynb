{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#import os\n",
    "from utils.model import Net_mask\n",
    "import torch\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model_ML_inf = Net_mask()\n",
    "model_MAP_e4 = Net_mask()\n",
    "model_MAP_e4_R100 = Net_mask()\n",
    "model_MAP_e5 = Net_mask()\n",
    "model_MAP_e6 = Net_mask()\n",
    "model_MAP_e6_R100 = Net_mask()\n",
    "model_ML_inf_reg = Net_mask()\n",
    "model_ML_inf_reg_10 = Net_mask()\n",
    "\n",
    "#model_ML_inf.load_state_dict(torch.load(f'../saved_models/models_infinite_data/ML/model_weights.pth'))\n",
    "#model_MAP_e4.load_state_dict(torch.load(f'../saved_models/finite_long_e4/map/0/model_weights.pth'))\n",
    "#model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e4_100/map/0/model_weights.pth'))\n",
    "#model_MAP_e5.load_state_dict(torch.load(f'../saved_models/finite_long_e5/map/0/model_weights.pth'))\n",
    "#model_MAP_e6.load_state_dict(torch.load(f'../saved_models/finite_long_e6/map/0/model_weights.pth'))\n",
    "#model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e6_100/map/0/model_weights.pth'))\n",
    "#model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_100/model_weights.pth'))\n",
    "#model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_10/model_weights.pth'))\n",
    "\n",
    "\n",
    "model_ML_inf.load_state_dict(torch.load(f'../saved_models/models_infinite_data/ML/model_weights.pth'))\n",
    "model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_100/model_weights.pth'))\n",
    "model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_10/model_weights.pth'))\n",
    "#model_MAP_e4.load_state_dict(torch.load(f'../saved_models/models_finite_data/e4/prior_10/model_weights.pth'))\n",
    "model_MAP_e4.load_state_dict(torch.load(f'../saved_models/testing/map/long/e4/0/model_weights.pth'))\n",
    "model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/models_finite_data/e4/prior_100/model_weights.pth'))\n",
    "#model_MAP_e5.load_state_dict(torch.load(f'../saved_models/models_finite_data/e5/prior_100/model_weights.pth'))\n",
    "model_MAP_e5.load_state_dict(torch.load(f'../saved_models/testing/map/long/e5/0/model_weights.pth'))\n",
    "model_MAP_e6.load_state_dict(torch.load(f'../saved_models/models_finite_data/e6/prior_1000/model_weights.pth'))\n",
    "model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/models_finite_data/e6/prior_100/model_weights.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tensor_D = torch.tensor(\n",
    "    [[1, -1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, -1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  1, -1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 1, -1, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 1, -1, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 1, -1, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 1, -1, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 1, -1, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 0, 1, -1],\n",
    "    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 1],], dtype=torch.float\n",
    ")\n",
    "tensor_Q_m  = torch.mm(torch.t(tensor_D), tensor_D)\n",
    "n_param = tensor_D.size(dim=0)\n",
    "#tau2 = 1000 # 1/tau2 is the noise added to the diagonal\n",
    "#tensor_Q_m_modified = tensor_Q_m + torch.eye(n_param)*(1./tau2)\n",
    "#sigma2_eps = 0.01  # 1/sigma2_eps is the factor before the likelihood\n",
    "#tensor_mu_m = torch.zeros(n_param)\n",
    "\n",
    "#tensor_Sigma_m = torch.inverse(tensor_Q_m_modified)\n",
    "#tensor_Sigma_eps = torch.eye(n_param)*sigma2_eps\n",
    "#tensor_mu_eps = tensor_mu_m "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "all_test_obses = torch.load(f'../data/test_observations/test_set_full/all_test_obses.pt')\n",
    "all_test_solutions = torch.load(f'../data/test_observations/test_set_full/all_test_solutions.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def loss(predicted, analytical):\n",
    "    difference = predicted - analytical\n",
    "    squared_error = torch.square(difference)\n",
    "    tensor_squared_error_sum = torch.sum(squared_error, dim=1)\n",
    "    tensor_squared_error_sum_all = torch.sum(tensor_squared_error_sum)\n",
    "    return tensor_squared_error_sum_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "max_points = 6\n",
    "n_data = all_test_obses.shape[1]\n",
    "\n",
    "f_list = list(range(0, 15)) + list(range(20, 23)) + list(range(60, 62)) + [81] + list(range(96, 100))\n",
    "f_length = len(f_list)\n",
    "n_bnn = f_length\n",
    "loss_RML_e4_all = torch.zeros(max_points, n_bnn)\n",
    "loss_RML_e5_all = torch.zeros(max_points, n_bnn)\n",
    "\n",
    "loss_ML_inf = torch.zeros(max_points)\n",
    "loss_ML_inf_reg = torch.zeros(max_points)\n",
    "loss_ML_inf_reg_10 = torch.zeros(max_points)\n",
    "loss_MAP_e4 = torch.zeros(max_points)\n",
    "loss_MAP_e4_R100 = torch.zeros(max_points)\n",
    "loss_MAP_e5 = torch.zeros(max_points)\n",
    "loss_MAP_e6 = torch.zeros(max_points)\n",
    "loss_MAP_e6_R100 = torch.zeros(max_points)\n",
    "\n",
    "loss_RML_e4_0 = torch.zeros(max_points)\n",
    "loss_RML_e4_n_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_median = torch.zeros(max_points)\n",
    "loss_RML_e4_variance = torch.zeros(max_points)\n",
    "loss_RML_e5_0 = torch.zeros(max_points)\n",
    "loss_RML_e5_n_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_median = torch.zeros(max_points)\n",
    "loss_RML_e5_variance = torch.zeros(max_points)\n",
    "\n",
    "for p in range(max_points):\n",
    "    test_set_points = all_test_obses[p]\n",
    "    test_set_solution = all_test_solutions[p]\n",
    "\n",
    "    #i_list = list(range(26)) + list(range(83, 100))\n",
    "    #i_list = list(range(12)) + list(range(96, 100))\n",
    "\n",
    "    pred_RML_e4_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    pred_RML_e5_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    \n",
    "    for idx, item in enumerate(f_list):\n",
    "        model_RML_e4 = Net_mask()\n",
    "        model_RML_e4.load_state_dict(torch.load(f'../saved_models/testing/rml/long/e4/{item}/model_weights.pth'))\n",
    "        pred_RML_e4_all[idx] = model_RML_e4(test_set_points)\n",
    "        loss_RML_e4_all[p,idx] = loss(pred_RML_e4_all[idx], test_set_solution)\n",
    "\n",
    "    #i_list = list(range(35)) + list(range(92, 100))\n",
    "    #i_list = list(range(12)) + list(range(96, 100))\n",
    "    for idx, item in enumerate(f_list):\n",
    "        model_RML_e5 = Net_mask()\n",
    "        model_RML_e5.load_state_dict(torch.load(f'../saved_models/testing/rml/long/e5/{item}/model_weights.pth'))\n",
    "        pred_RML_e5_all[idx] = model_RML_e5(test_set_points)\n",
    "        loss_RML_e5_all[p,idx] = loss(pred_RML_e5_all[idx], test_set_solution)\n",
    "\n",
    "    loss_ML_inf[p] = loss(model_ML_inf(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg[p] = loss(model_ML_inf_reg(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg_10[p] = loss(model_ML_inf_reg_10(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4[p] = loss(model_MAP_e4(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4_R100[p] = loss(model_MAP_e4_R100(test_set_points), test_set_solution)\n",
    "    loss_MAP_e5[p] = loss(model_MAP_e5(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6[p] = loss(model_MAP_e6(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6_R100[p] = loss(model_MAP_e6_R100(test_set_points), test_set_solution)\n",
    "\n",
    "    loss_RML_e4_0[p] = loss(pred_RML_e4_all[0], test_set_solution)\n",
    "    loss_RML_e4_n_mean[p] = torch.mean(loss_RML_e4_all[p], dim=0)\n",
    "    loss_RML_e4_mean[p] = loss(torch.mean(pred_RML_e4_all, dim=0), test_set_solution)\n",
    "    loss_RML_e4_median[p] = loss(torch.median(pred_RML_e4_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e4_variance[p] = torch.mean(torch.var(pred_RML_e4_all, dim=0))\n",
    "\n",
    "    loss_RML_e5_0[p] = loss(pred_RML_e5_all[0], test_set_solution)\n",
    "    loss_RML_e5_n_mean[p] = torch.mean(loss_RML_e5_all[p], dim=0)\n",
    "    loss_RML_e5_mean[p] = loss(torch.mean(pred_RML_e5_all, dim=0), test_set_solution)\n",
    "    loss_RML_e5_median[p] = loss(torch.median(pred_RML_e5_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e5_variance[p] = torch.mean(torch.var(pred_RML_e5_all, dim=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "loss_RML_e4_all.shape\n",
    "print(torch.min(loss_RML_e4_all[0]))\n",
    "print(torch.min(loss_RML_e4_all, dim=1)[0])\n",
    "print(torch.quantile(loss_RML_e4_all, 0.1, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all[0], 0.1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.5, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.9, dim=1))\n",
    "print(torch.max(loss_RML_e4_all, dim=1)[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2825.3296, grad_fn=<MinBackward1>)\n",
      "tensor([2825.3296,  674.7759,  496.7845,  435.8459,  293.0797,  200.7890],\n",
      "       grad_fn=<MinBackward0>)\n",
      "tensor([3232.9458,  714.1666,  544.5178,  452.3090,  315.3419,  216.2378],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor(3232.9458, grad_fn=<SqueezeBackward3>)\n",
      "tensor([3813.0488,  849.4698,  605.1540,  488.5688,  359.8881,  238.2173],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([4594.9692, 1167.3317,  745.1271,  580.7892,  383.4521,  268.8664],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([5037.9375, 1331.6447,  809.1343,  605.6172,  423.2136,  290.1434],\n",
      "       grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "title = f'{\"Model/statistic\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":15} |'\n",
    "#string_ML_inf_reg = f'{\"ML-inf-reg\":15} | {\"inf\":4} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":15} |'\n",
    "string_ML_inf_reg_10 = f'{\"ML-inf-reg_10\":15} |'\n",
    "\n",
    "string_MAP_e4 = f'{\"MAP-e4\":15} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":15} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":15} |'\n",
    "string_MAP_e6 = f'{\"MAP-e6\":15} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":15} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-1\":15} |'\n",
    "string_RML_e4_n_mean = f'{\"RML-e4-n-mean\":15} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":15} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":15} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-1\":15} |'\n",
    "string_RML_e5_n_mean = f'{\"RML-e5-n-mean\":15} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":15} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":15} |'\n",
    "\n",
    "#string_RML_e6_0 = f'{\"RML-e6-0\":15} | {\"1e6\":4} |'\n",
    "#string_RML_e6_mean = f'{\"RML-e6-mean\":15} | {\"1e6\":4} |'\n",
    "#string_RML_e6_median = f'{\"RML-e6-median\":15} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":15} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":15} |'\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_ML_inf += f' {loss_ML_inf[i]:8.2f} |' \n",
    "    string_ML_inf_reg += f' {loss_ML_inf_reg[i]:8.2f} |' \n",
    "    string_ML_inf_reg_10 += f' {loss_ML_inf_reg_10[i]:8.2f} |' \n",
    "\n",
    "    string_MAP_e4 += f' {loss_MAP_e4[i]:8.2f} |' \n",
    "    string_MAP_e4_R100 += f' {loss_MAP_e4_R100[i]:8.2f} |' \n",
    "    string_MAP_e5 += f' {loss_MAP_e5[i]:8.2f} |' \n",
    "    string_MAP_e6 += f' {loss_MAP_e6[i]:8.2f} |' \n",
    "    string_MAP_e6_R100 += f' {loss_MAP_e6_R100[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e4_0 += f' {loss_RML_e4_0[i]:8.2f} |' \n",
    "    string_RML_e4_n_mean += f' {loss_RML_e4_n_mean[i]:8.2f} |'\n",
    "    string_RML_e4_mean += f' {loss_RML_e4_mean[i]:8.2f} |' \n",
    "    string_RML_e4_median += f' {loss_RML_e4_median[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e5_0 += f' {loss_RML_e5_0[i]:8.2f} |' \n",
    "    string_RML_e5_n_mean += f' {loss_RML_e5_n_mean[i]:8.2f} |'\n",
    "    string_RML_e5_mean += f' {loss_RML_e5_mean[i]:8.2f} |' \n",
    "    string_RML_e5_median += f' {loss_RML_e5_median[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e4_var += f' {loss_RML_e4_variance[i]:8.4f} |' \n",
    "    string_RML_e5_var += f' {loss_RML_e5_variance[i]:8.4f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*83\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_ML_inf_reg_10); total_string+=string_ML_inf_reg_10+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e4_R100); total_string+=string_MAP_e4_R100+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_MAP_e6); total_string+=string_MAP_e6+'\\n'\n",
    "#print(string_MAP_e6_R100); total_string+=string_MAP_e6_R100+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e4_var); total_string+=string_RML_e4_var+'\\n'\n",
    "#print(string_RML_e5_var); total_string+=string_RML_e5_var+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model/statistic | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "ML-inf          |   625.19 |    65.79 |   192.65 |   144.46 |    77.31 |    37.18 |\n",
      "MAP-inf         |   443.55 |    41.70 |   150.94 |   100.98 |    47.48 |    22.96 |\n",
      "-----------------------------------------------------------------------------------\n",
      "MAP-e4          |  1257.94 |   140.77 |   207.49 |   153.29 |    82.61 |    39.82 |\n",
      "MAP-e5          |   936.00 |   114.62 |   208.32 |   162.86 |    79.37 |    36.78 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4-n-mean   |  3857.64 |   920.45 |   626.24 |   504.89 |   353.79 |   239.96 |\n",
      "RML-e4-mean     |  3708.28 |   727.88 |   423.93 |   305.54 |   171.14 |    82.97 |\n",
      "RML-e4-median   |  3744.62 |   741.76 |   434.28 |   316.51 |   179.25 |    90.85 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e5-n-mean   |  1751.37 |   239.29 |   258.75 |   198.43 |   117.61 |    65.93 |\n",
      "RML-e5-mean     |  1666.62 |   180.20 |   207.23 |   152.81 |    77.45 |    33.28 |\n",
      "RML-e5-median   |  1683.39 |   185.98 |   209.56 |   154.45 |    78.33 |    33.90 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "with open('../figures/plot_table_prediction_error/plot_table_prediction_error.txt', 'w') as outfile:\n",
    "    outfile.write('\\n\\n' + total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "title1 = f'{\"Model\":15} | {\"N train data\":12} | {\"Regularization\":14} | {\"Comment\":34} |'\n",
    "title2 = f'{\"Statistic\":15} | {\"\":12} | {\"\":14} | {\"Comment\":34} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":15} | {\"Infinite\":12} | {\"None\":14} | {\"Maximum likelihood model\":34} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":15} | {\"Infinite\":12} | {\"L_2\":14} | {\"Model with L_2 regularization\":34} |'\n",
    "\n",
    "#string_MAP_e4 = f'{\"MAP-e4\":13} | {\"1e4\":4} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":15} | {\"10^4\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^4 data\":34} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":15} | {\"10^5\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^5 data\":34} |'\n",
    "#string_MAP_e6 = f'{\"MAP-e6\":13} | {\"1e6\":4} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":15} | {\"10^6\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^6 data\":34} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-1\":15} | {\"10^4\":12} | {\"L_2 (RML)\":14} | {\"RML model number 1 with 10^4 data\":34} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":15} | {\"\":12} | {\"\":14} | {\"Median of RML-e4-1 to RML-e4-25\":34} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-1\":15} | {\"10^5\":12} | {\"L_2 (RML)\":14} | {\"RML model number 1 with 10^5 data\":34} |'\n",
    "#string_RML_e5_n_mean = f'{\"RML-e5-n_mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e5-1 to RML-e5-25\":34} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e5-1 to RML-e5-25\":34} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":15} | {\"\":12} | {\"\":14} | {\"Median of RML-e5-1 to RML-e5-25\":34} |'\n",
    "\n",
    "#string_RML_e6_0 = f'{\"RML-e6-0\":13} | {\"1e6\":4} |'\n",
    "#string_RML_e6_mean = f'{\"RML-e6-mean\":13} | {\"1e6\":4} |'\n",
    "#string_RML_e6_median = f'{\"RML-e6-median\":13} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":15} | {\"\":12} | {\"\":14} | {\"Variance of RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":15} | {\"\":12} | {\"\":14} | {\"Variance of RML-e5-1 to RML-e5-25\":34} |'\n",
    "\n",
    "\n",
    "string_break = '-'*86\n",
    "total_string = \"\"\n",
    "\n",
    "print(title1); total_string+=title1+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_MAP_e4_R100); total_string+=string_MAP_e4_R100+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_MAP_e6_R100); total_string+=string_MAP_e6_R100+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "#print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "#print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "#print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "#print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(title2); total_string+=title2+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "#print(string_RML_e4_var); total_string+=string_RML_e4_var+'\\n'\n",
    "#print(string_RML_e5_var); total_string+=string_RML_e5_var+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | N train data | Regularization | Comment                            |\n",
      "--------------------------------------------------------------------------------------\n",
      "ML-inf          | Infinite     | None           | Maximum likelihood model           |\n",
      "MAP-inf         | Infinite     | L_2            | Model with L_2 regularization      |\n",
      "MAP-e4          | 10^4         | L_2            | L_2 reg. trained with 10^4 data    |\n",
      "MAP-e5          | 10^5         | L_2            | L_2 reg. trained with 10^5 data    |\n",
      "RML-e4-1        | 10^4         | L_2 (RML)      | RML model number 1 with 10^4 data  |\n",
      "RML-e5-1        | 10^5         | L_2 (RML)      | RML model number 1 with 10^5 data  |\n",
      "--------------------------------------------------------------------------------------\n",
      "Statistic       |              |                | Comment                            |\n",
      "--------------------------------------------------------------------------------------\n",
      "RML-e4-mean     |              |                | Mean of RML-e4-1 to RML-e4-25      |\n",
      "RML-e4-median   |              |                | Median of RML-e4-1 to RML-e4-25    |\n",
      "RML-e5-mean     |              |                | Mean of RML-e5-1 to RML-e5-25      |\n",
      "RML-e5-median   |              |                | Median of RML-e5-1 to RML-e5-25    |\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with open('../figures/plot_table_prediction_error/plot_table_description.txt', 'w') as outfile:\n",
    "    outfile.write('\\n\\n' + total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\n",
    "title = f'{\"Percentile\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "\n",
    "loss_RML_e4_all.shape\n",
    "print(torch.min(loss_RML_e4_all, dim=1)[0])\n",
    "print(torch.quantile(loss_RML_e4_all, 0.1, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.5, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.9, dim=1))\n",
    "print(torch.max(loss_RML_e4_all, dim=1)[0])\n",
    "\n",
    "string_RML_e4_min = f'{\"RML-e4-min\":15} |'\n",
    "string_RML_e4_p10 = f'{\"RML-e4-p10\":15} |'\n",
    "string_RML_e4_p50 = f'{\"RML-e4-p50\":15} |'\n",
    "string_RML_e4_p90 = f'{\"RML-e4-p90\":15} |'\n",
    "string_RML_e4_max = f'{\"RML-e4-max\":15} |'\n",
    "\n",
    "string_RML_e5_min = f'{\"RML-e5-min\":15} |'\n",
    "string_RML_e5_p10 = f'{\"RML-e5-p10\":15} |'\n",
    "string_RML_e5_p50 = f'{\"RML-e5-p50\":15} |'\n",
    "string_RML_e5_p90 = f'{\"RML-e5-p90\":15} |'\n",
    "string_RML_e5_max = f'{\"RML-e5-max\":15} |'\n",
    "\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_RML_e4_min += f' {torch.min(loss_RML_e4_all[i]):8.2f} |' \n",
    "    string_RML_e4_p10 += f' {torch.quantile(loss_RML_e4_all[i], 0.1):8.2f} |'\n",
    "    string_RML_e4_p50 += f' {torch.quantile(loss_RML_e4_all[i], 0.5):8.2f} |'\n",
    "    string_RML_e4_p90 += f' {torch.quantile(loss_RML_e4_all[i], 0.9):8.2f} |'\n",
    "    string_RML_e4_max += f' {torch.max(loss_RML_e4_all[i]):8.2f} |' \n",
    "\n",
    "    string_RML_e5_min += f' {torch.min(loss_RML_e5_all[i]):8.2f} |' \n",
    "    string_RML_e5_p10 += f' {torch.quantile(loss_RML_e5_all[i], 0.1):8.2f} |'\n",
    "    string_RML_e5_p50 += f' {torch.quantile(loss_RML_e5_all[i], 0.5):8.2f} |'\n",
    "    string_RML_e5_p90 += f' {torch.quantile(loss_RML_e5_all[i], 0.9):8.2f} |'\n",
    "    string_RML_e5_max += f' {torch.max(loss_RML_e5_all[i]):8.2f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*83\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_min); total_string+=string_RML_e4_min+'\\n'\n",
    "print(string_RML_e4_p10); total_string+=string_RML_e4_p10+'\\n'\n",
    "print(string_RML_e4_p50); total_string+=string_RML_e4_p50+'\\n'\n",
    "print(string_RML_e4_p90); total_string+=string_RML_e4_p90+'\\n'\n",
    "print(string_RML_e4_max); total_string+=string_RML_e4_max+'\\n'\n",
    "\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_min); total_string+=string_RML_e5_min+'\\n'\n",
    "print(string_RML_e5_p10); total_string+=string_RML_e5_p10+'\\n'\n",
    "print(string_RML_e5_p50); total_string+=string_RML_e5_p50+'\\n'\n",
    "print(string_RML_e5_p90); total_string+=string_RML_e5_p90+'\\n'\n",
    "print(string_RML_e5_max); total_string+=string_RML_e5_max+'\\n'\n",
    "\n",
    "print(string_break); total_string+=string_break+'\\n'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2825.3296,  674.7759,  496.7845,  435.8459,  293.0797,  200.7890],\n",
      "       grad_fn=<MinBackward0>)\n",
      "tensor([3232.9458,  714.1666,  544.5178,  452.3090,  315.3419,  216.2378],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([3813.0488,  849.4698,  605.1540,  488.5688,  359.8881,  238.2173],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([4594.9692, 1167.3317,  745.1271,  580.7892,  383.4521,  268.8664],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([5037.9375, 1331.6447,  809.1343,  605.6172,  423.2136,  290.1434],\n",
      "       grad_fn=<MaxBackward0>)\n",
      "Percentile      | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4-min      |  2825.33 |   674.78 |   496.78 |   435.85 |   293.08 |   200.79 |\n",
      "RML-e4-p10      |  3232.95 |   714.17 |   544.52 |   452.31 |   315.34 |   216.24 |\n",
      "RML-e4-p50      |  3813.05 |   849.47 |   605.15 |   488.57 |   359.89 |   238.22 |\n",
      "RML-e4-p90      |  4594.97 |  1167.33 |   745.13 |   580.79 |   383.45 |   268.87 |\n",
      "RML-e4-max      |  5037.94 |  1331.64 |   809.13 |   605.62 |   423.21 |   290.14 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e5-min      |  1097.83 |   158.61 |   231.62 |   169.54 |   102.23 |    53.94 |\n",
      "RML-e5-p10      |  1243.97 |   189.30 |   241.00 |   182.71 |   106.96 |    57.83 |\n",
      "RML-e5-p50      |  1653.89 |   223.31 |   257.94 |   196.26 |   115.66 |    66.03 |\n",
      "RML-e5-p90      |  2299.50 |   294.13 |   274.52 |   212.23 |   132.21 |    75.14 |\n",
      "RML-e5-max      |  2759.27 |   374.78 |   301.08 |   238.74 |   139.89 |    80.56 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.4 64-bit ('pytorch_env': conda)"
  },
  "interpreter": {
   "hash": "24726422bde522ec9d6b8250d1636c6a7c473f035d7185ba3e11c63b1681e397"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}