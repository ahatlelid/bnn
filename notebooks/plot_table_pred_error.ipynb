{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 480,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#import os\n",
    "from utils.model import Net_mask\n",
    "import torch\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "source": [
    "model_ML_inf = Net_mask()\n",
    "model_MAP_e4 = Net_mask()\n",
    "model_MAP_e4_R100 = Net_mask()\n",
    "model_MAP_e5 = Net_mask()\n",
    "model_MAP_e6 = Net_mask()\n",
    "model_MAP_e6_R100 = Net_mask()\n",
    "model_ML_inf_reg = Net_mask()\n",
    "model_ML_inf_reg_10 = Net_mask()\n",
    "\n",
    "#model_ML_inf.load_state_dict(torch.load(f'../saved_models/models_infinite_data/ML/model_weights.pth'))\n",
    "#model_MAP_e4.load_state_dict(torch.load(f'../saved_models/finite_long_e4/map/0/model_weights.pth'))\n",
    "#model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e4_100/map/0/model_weights.pth'))\n",
    "#model_MAP_e5.load_state_dict(torch.load(f'../saved_models/finite_long_e5/map/0/model_weights.pth'))\n",
    "#model_MAP_e6.load_state_dict(torch.load(f'../saved_models/finite_long_e6/map/0/model_weights.pth'))\n",
    "#model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/finite_long_e6_100/map/0/model_weights.pth'))\n",
    "#model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_100/model_weights.pth'))\n",
    "#model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_10/model_weights.pth'))\n",
    "\n",
    "\n",
    "model_ML_inf.load_state_dict(torch.load(f'../saved_models/models_infinite_data/ML/model_weights.pth'))\n",
    "model_ML_inf_reg.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_100/model_weights.pth'))\n",
    "model_ML_inf_reg_10.load_state_dict(torch.load(f'../saved_models/models_infinite_data/MAP_inf_prior_10/model_weights.pth'))\n",
    "#model_MAP_e4.load_state_dict(torch.load(f'../saved_models/models_finite_data/e4/prior_10/model_weights.pth'))\n",
    "model_MAP_e4.load_state_dict(torch.load(f'../saved_models/testing/map/long/e4/0/model_weights.pth'))\n",
    "model_MAP_e4_R100.load_state_dict(torch.load(f'../saved_models/models_finite_data/e4/prior_100/model_weights.pth'))\n",
    "#model_MAP_e5.load_state_dict(torch.load(f'../saved_models/models_finite_data/e5/prior_100/model_weights.pth'))\n",
    "model_MAP_e5.load_state_dict(torch.load(f'../saved_models/testing/map/long/e5/0/model_weights.pth'))\n",
    "model_MAP_e6.load_state_dict(torch.load(f'../saved_models/models_finite_data/e6/prior_1000/model_weights.pth'))\n",
    "model_MAP_e6_R100.load_state_dict(torch.load(f'../saved_models/models_finite_data/e6/prior_100/model_weights.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 482
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "source": [
    "tensor_D = torch.tensor(\n",
    "    [[1, -1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, -1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  1, -1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 1, -1, 0, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 1, -1, 0, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 1, -1, 0, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 1, -1, 0, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 1, -1, 0],\n",
    "    [0, 0,  0, 0, 0, 0, 0, 0, 1, -1],\n",
    "    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 1],], dtype=torch.float\n",
    ")\n",
    "tensor_Q_m  = torch.mm(torch.t(tensor_D), tensor_D)\n",
    "n_param = tensor_D.size(dim=0)\n",
    "#tau2 = 1000 # 1/tau2 is the noise added to the diagonal\n",
    "#tensor_Q_m_modified = tensor_Q_m + torch.eye(n_param)*(1./tau2)\n",
    "#sigma2_eps = 0.01  # 1/sigma2_eps is the factor before the likelihood\n",
    "#tensor_mu_m = torch.zeros(n_param)\n",
    "\n",
    "#tensor_Sigma_m = torch.inverse(tensor_Q_m_modified)\n",
    "#tensor_Sigma_eps = torch.eye(n_param)*sigma2_eps\n",
    "#tensor_mu_eps = tensor_mu_m "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "source": [
    "all_test_obses = torch.load(f'../data/test_observations/test_set_full/all_test_obses.pt')\n",
    "all_test_solutions = torch.load(f'../data/test_observations/test_set_full/all_test_solutions.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "source": [
    "def loss(predicted, analytical):\n",
    "    difference = predicted - analytical\n",
    "    squared_error = torch.square(difference)\n",
    "    tensor_squared_error_sum = torch.sum(squared_error, dim=1)\n",
    "    tensor_squared_error_sum_all = torch.sum(tensor_squared_error_sum)\n",
    "    return tensor_squared_error_sum_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "source": [
    "max_points = 6\n",
    "n_data = all_test_obses.shape[1]\n",
    "\n",
    "#f_list = list(range(0, 20)) + list(range(20, 28)) + list(range(60, 65)) + [81, 82] + list(range(96, 100))\n",
    "#f_list = list(range(0, 19)) + list(range(20, 27)) + list(range(60, 65)) + [81, 82] + list(range(96, 100))\n",
    "#f_list = list(range(31)) + list(range(60, 68)) + [70] + list(range(80, 85)) + list(range(92, 100))\n",
    "f_list = list(range(34)) + list(range(60, 72)) + list(range(80,88)) + list(range(92, 100))\n",
    "f_length = len(f_list)\n",
    "n_bnn = f_length\n",
    "loss_RML_e4_all = torch.zeros(max_points, n_bnn)\n",
    "loss_RML_e5_all = torch.zeros(max_points, n_bnn)\n",
    "\n",
    "loss_ML_inf = torch.zeros(max_points)\n",
    "loss_ML_inf_reg = torch.zeros(max_points)\n",
    "loss_ML_inf_reg_10 = torch.zeros(max_points)\n",
    "loss_MAP_e4 = torch.zeros(max_points)\n",
    "loss_MAP_e4_R100 = torch.zeros(max_points)\n",
    "loss_MAP_e5 = torch.zeros(max_points)\n",
    "loss_MAP_e6 = torch.zeros(max_points)\n",
    "loss_MAP_e6_R100 = torch.zeros(max_points)\n",
    "\n",
    "loss_RML_e4_0 = torch.zeros(max_points)\n",
    "loss_RML_e4_n_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_mean = torch.zeros(max_points)\n",
    "loss_RML_e4_median = torch.zeros(max_points)\n",
    "loss_RML_e4_variance = torch.zeros(max_points)\n",
    "loss_RML_e5_0 = torch.zeros(max_points)\n",
    "loss_RML_e5_n_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_mean = torch.zeros(max_points)\n",
    "loss_RML_e5_median = torch.zeros(max_points)\n",
    "loss_RML_e5_variance = torch.zeros(max_points)\n",
    "\n",
    "for p in range(max_points):\n",
    "    test_set_points = all_test_obses[p]\n",
    "    test_set_solution = all_test_solutions[p]\n",
    "\n",
    "    #i_list = list(range(26)) + list(range(83, 100))\n",
    "    #i_list = list(range(12)) + list(range(96, 100))\n",
    "\n",
    "    pred_RML_e4_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    pred_RML_e5_all = torch.zeros(n_bnn, n_data, n_param)\n",
    "    \n",
    "    for idx, item in enumerate(f_list):\n",
    "        model_RML_e4 = Net_mask()\n",
    "        model_RML_e4.load_state_dict(torch.load(f'../saved_models/testing/rml/long/e4/{item}/model_weights.pth'))\n",
    "        pred_RML_e4_all[idx] = model_RML_e4(test_set_points)\n",
    "        loss_RML_e4_all[p,idx] = loss(pred_RML_e4_all[idx], test_set_solution)\n",
    "\n",
    "    #i_list = list(range(35)) + list(range(92, 100))\n",
    "    #i_list = list(range(12)) + list(range(96, 100))\n",
    "    for idx, item in enumerate(f_list):\n",
    "        model_RML_e5 = Net_mask()\n",
    "        model_RML_e5.load_state_dict(torch.load(f'../saved_models/testing/rml/long/e5/{item}/model_weights.pth'))\n",
    "        pred_RML_e5_all[idx] = model_RML_e5(test_set_points)\n",
    "        loss_RML_e5_all[p,idx] = loss(pred_RML_e5_all[idx], test_set_solution)\n",
    "\n",
    "    loss_ML_inf[p] = loss(model_ML_inf(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg[p] = loss(model_ML_inf_reg(test_set_points), test_set_solution)\n",
    "    loss_ML_inf_reg_10[p] = loss(model_ML_inf_reg_10(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4[p] = loss(model_MAP_e4(test_set_points), test_set_solution)\n",
    "    loss_MAP_e4_R100[p] = loss(model_MAP_e4_R100(test_set_points), test_set_solution)\n",
    "    loss_MAP_e5[p] = loss(model_MAP_e5(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6[p] = loss(model_MAP_e6(test_set_points), test_set_solution)\n",
    "    loss_MAP_e6_R100[p] = loss(model_MAP_e6_R100(test_set_points), test_set_solution)\n",
    "\n",
    "    loss_RML_e4_0[p] = loss(pred_RML_e4_all[0], test_set_solution)\n",
    "    loss_RML_e4_n_mean[p] = torch.mean(loss_RML_e4_all[p], dim=0)\n",
    "    loss_RML_e4_mean[p] = loss(torch.mean(pred_RML_e4_all, dim=0), test_set_solution)\n",
    "    loss_RML_e4_median[p] = loss(torch.median(pred_RML_e4_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e4_variance[p] = torch.mean(torch.var(pred_RML_e4_all, dim=0))\n",
    "\n",
    "    loss_RML_e5_0[p] = loss(pred_RML_e5_all[0], test_set_solution)\n",
    "    loss_RML_e5_n_mean[p] = torch.mean(loss_RML_e5_all[p], dim=0)\n",
    "    loss_RML_e5_mean[p] = loss(torch.mean(pred_RML_e5_all, dim=0), test_set_solution)\n",
    "    loss_RML_e5_median[p] = loss(torch.median(pred_RML_e5_all, dim=0)[0], test_set_solution)\n",
    "    loss_RML_e5_variance[p] = torch.mean(torch.var(pred_RML_e5_all, dim=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "source": [
    "loss_RML_e4_all.shape\n",
    "print(torch.min(loss_RML_e4_all[0]))\n",
    "print(torch.min(loss_RML_e4_all, dim=1)[0])\n",
    "print(torch.quantile(loss_RML_e4_all, 0.1, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all[0], 0.1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.5, dim=1))\n",
    "print(torch.quantile(loss_RML_e4_all, 0.9, dim=1))\n",
    "print(torch.max(loss_RML_e4_all, dim=1)[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2825.3296, grad_fn=<MinBackward1>)\n",
      "tensor([2825.3296,  674.7759,  496.7845,  435.8459,  293.0797,  200.7890],\n",
      "       grad_fn=<MinBackward0>)\n",
      "tensor([3303.4282,  732.1938,  546.3433,  453.1607,  315.4135,  216.8201],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor(3303.4282, grad_fn=<SqueezeBackward3>)\n",
      "tensor([3725.0298,  843.9620,  605.1540,  488.5688,  354.2705,  237.7041],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([4555.3496, 1167.3148,  742.6432,  580.5989,  388.9688,  274.4425],\n",
      "       grad_fn=<SqueezeBackward3>)\n",
      "tensor([5037.9375, 1331.6447,  809.1343,  607.4666,  424.3146,  290.1434],\n",
      "       grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "source": [
    "title = f'{\"Model/statistic\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":15} |'\n",
    "#string_ML_inf_reg = f'{\"ML-inf-reg\":15} | {\"inf\":4} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":15} |'\n",
    "string_ML_inf_reg_10 = f'{\"ML-inf-reg_10\":15} |'\n",
    "\n",
    "string_MAP_e4 = f'{\"MAP-e4\":15} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":15} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":15} |'\n",
    "string_MAP_e6 = f'{\"MAP-e6\":15} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":15} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-1\":15} |'\n",
    "string_RML_e4_n_mean = f'{\"RML-e4\":15} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":15} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":15} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-1\":15} |'\n",
    "string_RML_e5_n_mean = f'{\"RML-e5\":15} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":15} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":15} |'\n",
    "\n",
    "#string_RML_e6_0 = f'{\"RML-e6-0\":15} | {\"1e6\":4} |'\n",
    "#string_RML_e6_mean = f'{\"RML-e6-mean\":15} | {\"1e6\":4} |'\n",
    "#string_RML_e6_median = f'{\"RML-e6-median\":15} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":15} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":15} |'\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_ML_inf += f' {loss_ML_inf[i]:8.2f} |' \n",
    "    string_ML_inf_reg += f' {loss_ML_inf_reg[i]:8.2f} |' \n",
    "    string_ML_inf_reg_10 += f' {loss_ML_inf_reg_10[i]:8.2f} |' \n",
    "\n",
    "    string_MAP_e4 += f' {loss_MAP_e4[i]:8.2f} |' \n",
    "    string_MAP_e4_R100 += f' {loss_MAP_e4_R100[i]:8.2f} |' \n",
    "    string_MAP_e5 += f' {loss_MAP_e5[i]:8.2f} |' \n",
    "    string_MAP_e6 += f' {loss_MAP_e6[i]:8.2f} |' \n",
    "    string_MAP_e6_R100 += f' {loss_MAP_e6_R100[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e4_0 += f' {loss_RML_e4_0[i]:8.2f} |' \n",
    "    string_RML_e4_n_mean += f' {loss_RML_e4_n_mean[i]:8.2f} |'\n",
    "    string_RML_e4_mean += f' {loss_RML_e4_mean[i]:8.2f} |' \n",
    "    string_RML_e4_median += f' {loss_RML_e4_median[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e5_0 += f' {loss_RML_e5_0[i]:8.2f} |' \n",
    "    string_RML_e5_n_mean += f' {loss_RML_e5_n_mean[i]:8.2f} |'\n",
    "    string_RML_e5_mean += f' {loss_RML_e5_mean[i]:8.2f} |' \n",
    "    string_RML_e5_median += f' {loss_RML_e5_median[i]:8.2f} |' \n",
    "\n",
    "    string_RML_e4_var += f' {loss_RML_e4_variance[i]:8.4f} |' \n",
    "    string_RML_e5_var += f' {loss_RML_e5_variance[i]:8.4f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*83\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "#print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "#print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "#print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "#print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model/statistic | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4-mean     |  3691.63 |   716.44 |   417.96 |   301.08 |   167.55 |    81.17 |\n",
      "RML-e4-median   |  3716.53 |   726.48 |   427.76 |   311.34 |   175.98 |    88.02 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e5-mean     |  1709.34 |   178.40 |   204.06 |   150.79 |    77.05 |    32.68 |\n",
      "RML-e5-median   |  1749.24 |   185.33 |   205.76 |   151.63 |    77.76 |    33.13 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "source": [
    "with open('../figures/plot_table_prediction_error/plot_table_prediction_error.txt', 'w') as outfile:\n",
    "    outfile.write('\\n\\n' + total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "source": [
    "title = f'{\"Model\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "total_string = \"\"\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "with open('../figures/plot_table_prediction_error/plot_table_prediction_error_inf.txt', 'w') as outfile_inf:\n",
    "    outfile_inf.write(total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "ML-inf          |   625.19 |    65.79 |   192.65 |   144.46 |    77.31 |    37.18 |\n",
      "MAP-inf         |   443.55 |    41.70 |   150.94 |   100.98 |    47.48 |    22.96 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "source": [
    "\n",
    "title = f'{\"Model\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "total_string = \"\"\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "#print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "#print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "with open('../figures/plot_table_prediction_error/plot_table_prediction_error_map.txt', 'w') as outfile_inf:\n",
    "    outfile_inf.write(total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "MAP-e4          |  1257.94 |   140.77 |   207.49 |   153.29 |    82.61 |    39.82 |\n",
      "MAP-e5          |   936.00 |   114.62 |   208.32 |   162.86 |    79.37 |    36.78 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "source": [
    "title = f'{\"Model\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "\n",
    "total_string = \"\"\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "#print(string_MAP_e4); total_string+=string_MAP_e4+'\\n'\n",
    "#print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "with open('../figures/plot_table_prediction_error/plot_table_prediction_error_RML_n.txt', 'w') as outfile_inf:\n",
    "    outfile_inf.write(total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4          |  3836.03 |   908.44 |   622.83 |   504.64 |   355.15 |   241.40 |\n",
      "RML-e5          |  1791.16 |   236.66 |   255.70 |   196.72 |   117.45 |    65.65 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "source": [
    "#with open('../figures/plot_table_prediction_error/plot_table_prediction_error_inf.txt', 'w') as outfile:\n",
    "#    outfile.write(total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "source": [
    "\n",
    "title = f'{\"Percentile\":15} | {\"1 point\":8} | {\"2 points\":8} | {\"3 points\":8} | {\"4 points\":8} | {\"5 points\":8} | {\"6 points\":8} |'\n",
    "title2 = f'{\"Mean\":15} {\"\":65} |'\n",
    "\n",
    "loss_RML_e4_all.shape\n",
    "#print(torch.min(loss_RML_e4_all, dim=1)[0])\n",
    "#print(torch.quantile(loss_RML_e4_all, 0.1, dim=1))\n",
    "#print(torch.quantile(loss_RML_e4_all, 0.5, dim=1))\n",
    "#print(torch.quantile(loss_RML_e4_all, 0.9, dim=1))\n",
    "#print(torch.max(loss_RML_e4_all, dim=1)[0])\n",
    "\n",
    "string_RML_e4_min = f'{\"RML-e4-min\":15} |'\n",
    "string_RML_e4_p10 = f'{\"RML-e4-p10\":15} |'\n",
    "string_RML_e4_p50 = f'{\"RML-e4-p50\":15} |'\n",
    "string_RML_e4_p90 = f'{\"RML-e4-p90\":15} |'\n",
    "string_RML_e4_max = f'{\"RML-e4-max\":15} |'\n",
    "\n",
    "string_RML_e5_min = f'{\"RML-e5-min\":15} |'\n",
    "string_RML_e5_p10 = f'{\"RML-e5-p10\":15} |'\n",
    "string_RML_e5_p50 = f'{\"RML-e5-p50\":15} |'\n",
    "string_RML_e5_p90 = f'{\"RML-e5-p90\":15} |'\n",
    "string_RML_e5_max = f'{\"RML-e5-max\":15} |'\n",
    "\n",
    "\n",
    "for i in range(max_points):\n",
    "\n",
    "    string_RML_e4_min += f' {torch.min(loss_RML_e4_all[i]):8.2f} |' \n",
    "    string_RML_e4_p10 += f' {torch.quantile(loss_RML_e4_all[i], 0.1):8.2f} |'\n",
    "    string_RML_e4_p50 += f' {torch.quantile(loss_RML_e4_all[i], 0.5):8.2f} |'\n",
    "    string_RML_e4_p90 += f' {torch.quantile(loss_RML_e4_all[i], 0.9):8.2f} |'\n",
    "    string_RML_e4_max += f' {torch.max(loss_RML_e4_all[i]):8.2f} |' \n",
    "\n",
    "    string_RML_e5_min += f' {torch.min(loss_RML_e5_all[i]):8.2f} |' \n",
    "    string_RML_e5_p10 += f' {torch.quantile(loss_RML_e5_all[i], 0.1):8.2f} |'\n",
    "    string_RML_e5_p50 += f' {torch.quantile(loss_RML_e5_all[i], 0.5):8.2f} |'\n",
    "    string_RML_e5_p90 += f' {torch.quantile(loss_RML_e5_all[i], 0.9):8.2f} |'\n",
    "    string_RML_e5_max += f' {torch.max(loss_RML_e5_all[i]):8.2f} |' \n",
    "\n",
    "\n",
    "string_break = '-'*83\n",
    "total_string = \"\"\n",
    "\n",
    "print(title); total_string+=title+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_min); total_string+=string_RML_e4_min+'\\n'\n",
    "print(string_RML_e4_p10); total_string+=string_RML_e4_p10+'\\n'\n",
    "print(string_RML_e4_p50); total_string+=string_RML_e4_p50+'\\n'\n",
    "print(string_RML_e4_p90); total_string+=string_RML_e4_p90+'\\n'\n",
    "print(string_RML_e4_max); total_string+=string_RML_e4_max+'\\n'\n",
    "\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_min); total_string+=string_RML_e5_min+'\\n'\n",
    "print(string_RML_e5_p10); total_string+=string_RML_e5_p10+'\\n'\n",
    "print(string_RML_e5_p50); total_string+=string_RML_e5_p50+'\\n'\n",
    "print(string_RML_e5_p90); total_string+=string_RML_e5_p90+'\\n'\n",
    "print(string_RML_e5_max); total_string+=string_RML_e5_max+'\\n'\n",
    "\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(title2); total_string+=title2+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentile      | 1 point  | 2 points | 3 points | 4 points | 5 points | 6 points |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4-min      |  2825.33 |   674.78 |   496.78 |   435.85 |   293.08 |   200.79 |\n",
      "RML-e4-p10      |  3303.43 |   732.19 |   546.34 |   453.16 |   315.41 |   216.82 |\n",
      "RML-e4-p50      |  3725.03 |   843.96 |   605.15 |   488.57 |   354.27 |   237.70 |\n",
      "RML-e4-p90      |  4555.35 |  1167.31 |   742.64 |   580.60 |   388.97 |   274.44 |\n",
      "RML-e4-max      |  5037.94 |  1331.64 |   809.13 |   607.47 |   424.31 |   290.14 |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e5-min      |  1097.83 |   150.56 |   214.30 |   169.54 |   102.23 |    53.94 |\n",
      "RML-e5-p10      |  1275.03 |   185.61 |   238.75 |   179.12 |   105.25 |    57.19 |\n",
      "RML-e5-p50      |  1822.45 |   223.31 |   256.06 |   195.52 |   115.66 |    65.85 |\n",
      "RML-e5-p90      |  2309.55 |   282.19 |   272.63 |   213.28 |   131.76 |    76.51 |\n",
      "RML-e5-max      |  2759.27 |   374.78 |   301.08 |   238.74 |   142.79 |    80.56 |\n",
      "-----------------------------------------------------------------------------------\n",
      "Mean                                                                              |\n",
      "-----------------------------------------------------------------------------------\n",
      "RML-e4          |  3836.03 |   908.44 |   622.83 |   504.64 |   355.15 |   241.40 |\n",
      "RML-e5          |  1791.16 |   236.66 |   255.70 |   196.72 |   117.45 |    65.65 |\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "source": [
    "\n",
    "with open('../figures/plot_table_prediction_error/plot_table_percentile.txt', 'w') as outfile:\n",
    "    outfile.write(total_string[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "source": [
    "\n",
    "title1 = f'{\"Model\":15} | {\"N train data\":12} | {\"Regularization\":14} | {\"Comment\":34} |'\n",
    "title2 = f'{\"Statistic\":15} | {\"\":12} | {\"\":14} | {\"Comment\":34} |'\n",
    "\n",
    "string_ML_inf = f'{\"ML-inf\":15} | {\"Infinite\":12} | {\"None\":14} | {\"Maximum likelihood model\":34} |'\n",
    "string_ML_inf_reg = f'{\"MAP-inf\":15} | {\"Infinite\":12} | {\"L_2\":14} | {\"Model with L_2 regularization\":34} |'\n",
    "\n",
    "#string_MAP_e4 = f'{\"MAP-e4\":13} | {\"1e4\":4} |'\n",
    "string_MAP_e4_R100 = f'{\"MAP-e4\":15} | {\"10^4\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^4 data\":34} |'\n",
    "string_MAP_e5 = f'{\"MAP-e5\":15} | {\"10^5\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^5 data\":34} |'\n",
    "#string_MAP_e6 = f'{\"MAP-e6\":13} | {\"1e6\":4} |'\n",
    "string_MAP_e6_R100 = f'{\"MAP-e6\":15} | {\"10^6\":12} | {\"L_2\":14} | {\"L_2 reg. trained with 10^6 data\":34} |'\n",
    "\n",
    "string_RML_e4_0 = f'{\"RML-e4-1\":15} | {\"10^4\":12} | {\"L_2 (RML)\":14} | {\"RML model number 1 with 10^4 data\":34} |'\n",
    "string_RML_e4_n_mean = f'{\"RML-e4-n-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of loss RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e4_mean = f'{\"RML-e4-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e4_median = f'{\"RML-e4-median\":15} | {\"\":12} | {\"\":14} | {\"Median of RML-e4-1 to RML-e4-25\":34} |'\n",
    "\n",
    "string_RML_e5_0 = f'{\"RML-e5-1\":15} | {\"10^5\":12} | {\"L_2 (RML)\":14} | {\"RML model number 1 with 10^5 data\":34} |'\n",
    "string_RML_e5_n_mean = f'{\"RML-e5-n-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of loss RML-e5-1 to RML-e5-25\":34} |'\n",
    "string_RML_e5_mean = f'{\"RML-e5-mean\":15} | {\"\":12} | {\"\":14} | {\"Mean of RML-e5-1 to RML-e5-25\":34} |'\n",
    "string_RML_e5_median = f'{\"RML-e5-median\":15} | {\"\":12} | {\"\":14} | {\"Median of RML-e5-1 to RML-e5-25\":34} |'\n",
    "\n",
    "#string_RML_e6_0 = f'{\"RML-e6-0\":13} | {\"1e6\":4} |'\n",
    "#string_RML_e6_mean = f'{\"RML-e6-mean\":13} | {\"1e6\":4} |'\n",
    "#string_RML_e6_median = f'{\"RML-e6-median\":13} | {\"1e6\":4} |'\n",
    "\n",
    "string_RML_e4_var = f'{\"RML-e4-var\":15} | {\"\":12} | {\"\":14} | {\"Variance of RML-e4-1 to RML-e4-25\":34} |'\n",
    "string_RML_e5_var = f'{\"RML-e5-var\":15} | {\"\":12} | {\"\":14} | {\"Variance of RML-e5-1 to RML-e5-25\":34} |'\n",
    "\n",
    "\n",
    "string_break = '-'*86\n",
    "total_string = \"\"\n",
    "\n",
    "print(title1); total_string+=title1+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_ML_inf); total_string+=string_ML_inf+'\\n'\n",
    "print(string_ML_inf_reg); total_string+=string_ML_inf_reg+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_MAP_e4_R100); total_string+=string_MAP_e4_R100+'\\n'\n",
    "print(string_MAP_e5); total_string+=string_MAP_e5+'\\n'\n",
    "#print(string_MAP_e6_R100); total_string+=string_MAP_e6_R100+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_0); total_string+=string_RML_e4_0+'\\n'\n",
    "#print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "#print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e5_0); total_string+=string_RML_e5_0+'\\n'\n",
    "#print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "#print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "#print(string_break); total_string+=string_break+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(title2); total_string+=title2+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "print(string_RML_e4_n_mean); total_string+=string_RML_e4_n_mean+'\\n'\n",
    "print(string_RML_e4_mean); total_string+=string_RML_e4_mean+'\\n'\n",
    "print(string_RML_e4_median); total_string+=string_RML_e4_median+'\\n'\n",
    "print(string_RML_e5_n_mean); total_string+=string_RML_e5_n_mean+'\\n'\n",
    "print(string_RML_e5_mean); total_string+=string_RML_e5_mean+'\\n'\n",
    "print(string_RML_e5_median); total_string+=string_RML_e5_median+'\\n'\n",
    "#print(string_RML_e4_var); total_string+=string_RML_e4_var+'\\n'\n",
    "#print(string_RML_e5_var); total_string+=string_RML_e5_var+'\\n'\n",
    "print(string_break); total_string+=string_break+'\\n'\n",
    "\n",
    "with open('../figures/plot_table_prediction_error/plot_table_description.txt', 'w') as outfile:\n",
    "    outfile.write('\\n\\n' + total_string[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model           | N train data | Regularization | Comment                            |\n",
      "--------------------------------------------------------------------------------------\n",
      "ML-inf          | Infinite     | None           | Maximum likelihood model           |\n",
      "MAP-inf         | Infinite     | L_2            | Model with L_2 regularization      |\n",
      "MAP-e4          | 10^4         | L_2            | L_2 reg. trained with 10^4 data    |\n",
      "MAP-e5          | 10^5         | L_2            | L_2 reg. trained with 10^5 data    |\n",
      "RML-e4-1        | 10^4         | L_2 (RML)      | RML model number 1 with 10^4 data  |\n",
      "RML-e5-1        | 10^5         | L_2 (RML)      | RML model number 1 with 10^5 data  |\n",
      "--------------------------------------------------------------------------------------\n",
      "Statistic       |              |                | Comment                            |\n",
      "--------------------------------------------------------------------------------------\n",
      "RML-e4-n-mean   |              |                | Mean of loss RML-e4-1 to RML-e4-25 |\n",
      "RML-e4-mean     |              |                | Mean of RML-e4-1 to RML-e4-25      |\n",
      "RML-e4-median   |              |                | Median of RML-e4-1 to RML-e4-25    |\n",
      "RML-e5-n-mean   |              |                | Mean of loss RML-e5-1 to RML-e5-25 |\n",
      "RML-e5-mean     |              |                | Mean of RML-e5-1 to RML-e5-25      |\n",
      "RML-e5-median   |              |                | Median of RML-e5-1 to RML-e5-25    |\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.4 64-bit ('pytorch_env': conda)"
  },
  "interpreter": {
   "hash": "24726422bde522ec9d6b8250d1636c6a7c473f035d7185ba3e11c63b1681e397"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}